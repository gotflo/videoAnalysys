{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Object Detection with Tactical Map Position Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import json\n",
    "import yaml\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known coordinates of each keypoint on the tactical map:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TLC</th>\n",
       "      <th>TRC</th>\n",
       "      <th>TR6MC</th>\n",
       "      <th>TL6MC</th>\n",
       "      <th>TR6ML</th>\n",
       "      <th>TL6ML</th>\n",
       "      <th>TR18MC</th>\n",
       "      <th>TL18MC</th>\n",
       "      <th>TR18ML</th>\n",
       "      <th>TL18ML</th>\n",
       "      <th>...</th>\n",
       "      <th>BR6MC</th>\n",
       "      <th>BL6MC</th>\n",
       "      <th>BR6ML</th>\n",
       "      <th>BL6ML</th>\n",
       "      <th>BR18MC</th>\n",
       "      <th>BL18MC</th>\n",
       "      <th>BR18ML</th>\n",
       "      <th>BL18ML</th>\n",
       "      <th>BRArc</th>\n",
       "      <th>BLArc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>15</td>\n",
       "      <td>291</td>\n",
       "      <td>188</td>\n",
       "      <td>116</td>\n",
       "      <td>189</td>\n",
       "      <td>116</td>\n",
       "      <td>221</td>\n",
       "      <td>84</td>\n",
       "      <td>221</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>189</td>\n",
       "      <td>117</td>\n",
       "      <td>221</td>\n",
       "      <td>84</td>\n",
       "      <td>221</td>\n",
       "      <td>84</td>\n",
       "      <td>182</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>501</td>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "      <td>521</td>\n",
       "      <td>521</td>\n",
       "      <td>463</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TLC  TRC  TR6MC  TL6MC  TR6ML  TL6ML  TR18MC  TL18MC  TR18ML  TL18ML  ...  \\\n",
       "x   15  291    188    116    189    116     221      84     221      84  ...   \n",
       "y   15   15     35     35     15     15      73      73      15      15  ...   \n",
       "\n",
       "   BR6MC  BL6MC  BR6ML  BL6ML  BR18MC  BL18MC  BR18ML  BL18ML  BRArc  BLArc  \n",
       "x    189    117    189    117     221      84     221      84    182    121  \n",
       "y    501    501    521    521     463     463     521     521    463    463  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical label of field keypoints (as defined when training the Yolo model):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alpha_label</th>\n",
       "      <th>TLC</th>\n",
       "      <th>TRC</th>\n",
       "      <th>TR6MC</th>\n",
       "      <th>TL6MC</th>\n",
       "      <th>TR6ML</th>\n",
       "      <th>TL6ML</th>\n",
       "      <th>TR18MC</th>\n",
       "      <th>TL18MC</th>\n",
       "      <th>TR18ML</th>\n",
       "      <th>TL18ML</th>\n",
       "      <th>...</th>\n",
       "      <th>BR6MC</th>\n",
       "      <th>BL6MC</th>\n",
       "      <th>BR6ML</th>\n",
       "      <th>BL6ML</th>\n",
       "      <th>BR18MC</th>\n",
       "      <th>BL18MC</th>\n",
       "      <th>BR18ML</th>\n",
       "      <th>BL18ML</th>\n",
       "      <th>BRArc</th>\n",
       "      <th>BLArc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_label</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha_label  TLC  TRC  TR6MC  TL6MC  TR6ML  TL6ML  TR18MC  TL18MC  TR18ML  \\\n",
       "num_label      0    1      2      3      4      5       6       7       8   \n",
       "\n",
       "alpha_label  TL18ML  ...  BR6MC  BL6MC  BR6ML  BL6ML  BR18MC  BL18MC  BR18ML  \\\n",
       "num_label         9  ...     18     19     20     21      22      23      24   \n",
       "\n",
       "alpha_label  BL18ML  BRArc  BLArc  \n",
       "num_label        25     26     27  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical label of the player, referee, and ball objects (as defined when training the Yolo model):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>alpha_label</th>\n",
       "      <th>player</th>\n",
       "      <th>referee</th>\n",
       "      <th>ball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_label</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "alpha_label  player  referee  ball\n",
       "num_label         0        1     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe dataframe representation are not used in what follows (original dictionary will be used)\n"
     ]
    }
   ],
   "source": [
    "# Get tactical map keypoints positions dictionary\n",
    "json_path = \"./pitch map labels position.json\"\n",
    "with open(json_path, 'r') as f:\n",
    "    keypoints_map_pos = json.load(f)\n",
    "\n",
    "# Get football field keypoints numerical to alphabetical mapping\n",
    "yaml_path = \"./config pitch dataset.yaml\"\n",
    "with open(yaml_path, 'r') as file:\n",
    "    classes_names_dic = yaml.safe_load(file)\n",
    "classes_names_dic = classes_names_dic['names']\n",
    "\n",
    "# Get football field keypoints numerical to alphabetical mapping\n",
    "yaml_path = \"./config players dataset.yaml\"\n",
    "with open(yaml_path, 'r') as file:\n",
    "    labels_dic = yaml.safe_load(file)\n",
    "labels_dic = labels_dic['names']\n",
    "\n",
    "print(\"Known coordinates of each keypoint on the tactical map:\")\n",
    "display(pd.DataFrame(keypoints_map_pos, index=['x','y']))\n",
    "print(\"Numerical label of field keypoints (as defined when training the Yolo model):\")\n",
    "display(pd.Series(classes_names_dic, name='alpha_label').reset_index().rename({\"index\":\"num_label\"}, axis=1).set_index(\"alpha_label\").transpose())\n",
    "print(\"Numerical label of the player, referee, and ball objects (as defined when training the Yolo model):\")\n",
    "display(pd.Series(labels_dic, name='alpha_label').reset_index().rename({\"index\":\"num_label\"}, axis=1).set_index(\"alpha_label\").transpose())\n",
    "print('\\033[1mThe dataframe representation are not used in what follows (original dictionary will be used)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video path\n",
    "video_path = './test vid.mp4'\n",
    "\n",
    "# Read tactical map image\n",
    "tac_map = cv2.imread('./tactical map.jpg')\n",
    "\n",
    "# Define team colors (based on chosen video)\n",
    "nbr_team_colors = 2\n",
    "colors_dic = {\n",
    "    \"Chelsea\":[(41,71,138), (220,98,88)], # Chelsea colors (Players kit color, GK kit color)\n",
    "    \"Man City\":[(144,200,255), (188,199,3)] # Man City colors (Players kit color, GK kit color)\n",
    "}\n",
    "\n",
    "colors_list = colors_dic[\"Chelsea\"]+colors_dic[\"Man City\"] # Define color list to be used for detected player team prediction\n",
    "color_list_lab = [skimage.color.rgb2lab([i/255 for i in c]) for c in colors_list] # Converting color_list to L*a*b* space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 players detection model\n",
    "model_players = YOLO(\"./models/Yolo8L Players/weights/best.pt\")\n",
    "\n",
    "# Load the YOLOv8 field keypoints detection model\n",
    "model_keypoints = YOLO(\"./models/Yolo8M Field Keypoints/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of frames: 1399\n",
      "Number of frames per second: 30.0\n",
      "Total duration of the video: 46.63333333333333 seconds\n",
      "Time between two frames: 0.03333333333333333 seconds\n"
     ]
    }
   ],
   "source": [
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error opening the video\")\n",
    "    exit()\n",
    "\n",
    "# Get the total number of frames\n",
    "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"Total number of frames:\", num_frames)\n",
    "\n",
    "# Get the number of frames per second\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(\"Number of frames per second:\", fps)\n",
    "\n",
    "# # Get the total duration of the video in seconds\n",
    "total_seconds = num_frames / fps\n",
    "print(\"Total duration of the video:\", total_seconds, \"seconds\")\n",
    "\n",
    "# Calculate the time between two frames in seconds\n",
    "time_between_frames = 1 / fps\n",
    "print(\"Time between two frames:\", time_between_frames, \"seconds\")\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     131.35      356.45]\n",
      " [     127.67      297.34]\n",
      " [     23.484      327.94]\n",
      " [     128.16      163.81]\n",
      " [     128.14       61.83]\n",
      " [     51.773      250.61]\n",
      " [     126.45      277.29]\n",
      " [     141.47       172.7]\n",
      " [     128.72      231.25]\n",
      " [      42.05       240.2]\n",
      " [     128.72      231.25]\n",
      " [     115.74      171.45]\n",
      " [      76.58      258.46]\n",
      " [     83.225      199.44]\n",
      " [     113.81      197.36]\n",
      " [     96.694      297.04]\n",
      " [     152.82      187.89]\n",
      " [     96.694      297.04]\n",
      " [     76.097      358.86]]\n"
     ]
    }
   ],
   "source": [
    "def match_players_positions(prev, courant):\n",
    "    # La vitesse maximale d'un joueur est estimée à 11 m/s dans un terrain de football\n",
    "    # Le temps séparant deux frame est 0.03333333333333333 s dans un terrain de football\n",
    "    # Donc la vitesse maximale d'un joueur entre deux frames est 11*0.0333333 = 0.36666666 m/tbf dans un terrain de football\n",
    "    # Enfin la vitesse maximale d'un joueur entre deux frames est 0.36666666*((546*314)/(120*90)) = 5.820629523799999 px/tbf dans le tactical map\n",
    "\n",
    "    prev = prev.tolist()\n",
    "    courant = courant.tolist()\n",
    "    \n",
    "    matched_positions = []\n",
    "    for prev_pos in prev:\n",
    "        max_diff = 5.820629523799999  # Initialize the minimum difference\n",
    "        matched_pos = [0, 0]  # Initialize the matched position\n",
    "        for curr_pos in courant:\n",
    "            # Calculate the absolute difference between x and y coordinates\n",
    "            diff_x = abs(prev_pos[0] - curr_pos[0])\n",
    "            diff_y = abs(prev_pos[1] - curr_pos[1])\n",
    "        \n",
    "            # Check if the absolute difference is less than the threshold and update the matched position\n",
    "            if diff_x < max_diff and diff_y < max_diff:\n",
    "                matched_pos = curr_pos\n",
    "                break\n",
    "        \n",
    "        matched_positions.append(matched_pos)\n",
    "\n",
    "    matched_positions = np.array(matched_positions)\n",
    "    return matched_positions\n",
    "\n",
    "# Example usage\n",
    "prev_positions = np.array([\n",
    "    [131.47, 356.35], [127.64, 297.45], [24.184, 327.18], [128.05, 163.62],\n",
    "    [128.13, 61.803], [51.621, 251.13], [126.25, 276.38], [141.45, 172.62],\n",
    "    [128.58, 231.36], [41.97, 240.09], [123.9, 234.74], [115.65, 171.73],\n",
    "    [76.562, 258.27], [83.214, 199.51], [113.75, 197.25], [96.69, 297.02],\n",
    "    [152.82, 187.75], [100.42, 298.41], [76.186, 358.93]\n",
    "])\n",
    "\n",
    "courant_positions = np.array([\n",
    "    [131.35, 356.45], [127.67, 297.34], [128.16, 163.81], [128.14, 61.83],\n",
    "    [126.45, 277.29], [23.484, 327.94], [42.05, 240.2], [128.72, 231.25],\n",
    "    [141.47, 172.7], [83.225, 199.44], [123.97, 234.89], [76.58, 258.46],\n",
    "    [115.74, 171.45], [51.773, 250.61], [96.694, 297.04], [113.81, 197.36],\n",
    "    [152.82, 187.89], [100.5, 298.7], [76.097, 358.86]\n",
    "])\n",
    "\n",
    "matched_positions = match_players_positions(prev_positions, courant_positions)\n",
    "print(matched_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 19 players, 1 referee, 1 ball, 1124.3ms\n",
      "Speed: 7.5ms preprocess, 1124.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 618.8ms\n",
      "Speed: 2.5ms preprocess, 618.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 1083.5ms\n",
      "Speed: 3.0ms preprocess, 1083.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 649.3ms\n",
      "Speed: 2.4ms preprocess, 649.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1118.2ms\n",
      "Speed: 2.5ms preprocess, 1118.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 580.5ms\n",
      "Speed: 2.0ms preprocess, 580.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 1 ball, 1119.7ms\n",
      "Speed: 4.0ms preprocess, 1119.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 624.2ms\n",
      "Speed: 3.0ms preprocess, 624.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 1 ball, 1077.4ms\n",
      "Speed: 3.2ms preprocess, 1077.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 601.5ms\n",
      "Speed: 3.4ms preprocess, 601.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 players, 1 referee, 1 ball, 1177.0ms\n",
      "Speed: 3.0ms preprocess, 1177.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 620.7ms\n",
      "Speed: 3.1ms preprocess, 620.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1109.7ms\n",
      "Speed: 3.0ms preprocess, 1109.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 606.8ms\n",
      "Speed: 2.0ms preprocess, 606.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1040.5ms\n",
      "Speed: 3.6ms preprocess, 1040.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 BL18MC, 581.4ms\n",
      "Speed: 3.2ms preprocess, 581.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1073.9ms\n",
      "Speed: 2.0ms preprocess, 1073.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 614.5ms\n",
      "Speed: 4.0ms preprocess, 614.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1114.8ms\n",
      "Speed: 3.4ms preprocess, 1114.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 627.1ms\n",
      "Speed: 6.0ms preprocess, 627.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1089.3ms\n",
      "Speed: 2.5ms preprocess, 1089.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 574.5ms\n",
      "Speed: 3.0ms preprocess, 574.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1134.3ms\n",
      "Speed: 2.5ms preprocess, 1134.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 603.3ms\n",
      "Speed: 4.0ms preprocess, 603.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1050.5ms\n",
      "Speed: 2.0ms preprocess, 1050.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 605.3ms\n",
      "Speed: 2.0ms preprocess, 605.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1123.9ms\n",
      "Speed: 3.2ms preprocess, 1123.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 616.1ms\n",
      "Speed: 2.2ms preprocess, 616.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1105.7ms\n",
      "Speed: 3.0ms preprocess, 1105.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 618.6ms\n",
      "Speed: 2.5ms preprocess, 618.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1162.1ms\n",
      "Speed: 3.0ms preprocess, 1162.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 624.9ms\n",
      "Speed: 3.0ms preprocess, 624.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1059.6ms\n",
      "Speed: 3.8ms preprocess, 1059.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 594.8ms\n",
      "Speed: 2.5ms preprocess, 594.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1009.7ms\n",
      "Speed: 3.5ms preprocess, 1009.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 615.3ms\n",
      "Speed: 3.3ms preprocess, 615.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1126.0ms\n",
      "Speed: 2.9ms preprocess, 1126.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 584.4ms\n",
      "Speed: 3.0ms preprocess, 584.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1110.7ms\n",
      "Speed: 3.0ms preprocess, 1110.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 620.9ms\n",
      "Speed: 3.5ms preprocess, 620.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1124.1ms\n",
      "Speed: 4.1ms preprocess, 1124.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 590.8ms\n",
      "Speed: 3.5ms preprocess, 590.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1130.2ms\n",
      "Speed: 3.0ms preprocess, 1130.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 626.8ms\n",
      "Speed: 3.4ms preprocess, 626.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1133.0ms\n",
      "Speed: 1.8ms preprocess, 1133.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 619.3ms\n",
      "Speed: 2.5ms preprocess, 619.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1122.5ms\n",
      "Speed: 3.0ms preprocess, 1122.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 624.7ms\n",
      "Speed: 3.0ms preprocess, 624.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1113.2ms\n",
      "Speed: 3.0ms preprocess, 1113.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 596.5ms\n",
      "Speed: 3.1ms preprocess, 596.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1150.7ms\n",
      "Speed: 2.0ms preprocess, 1150.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 579.7ms\n",
      "Speed: 2.5ms preprocess, 579.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 players, 1 referee, 1 ball, 1064.0ms\n",
      "Speed: 4.0ms preprocess, 1064.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 TLArc, 1 LMC, 1 BL18MC, 1 BLArc, 605.9ms\n",
      "Speed: 2.5ms preprocess, 605.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 1 ball, 1141.6ms\n",
      "Speed: 3.0ms preprocess, 1141.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 LMC, 1 BLArc, 612.0ms\n",
      "Speed: 2.3ms preprocess, 612.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 1 ball, 1148.0ms\n",
      "Speed: 2.0ms preprocess, 1148.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 LMC, 1 BL18MC, 1 BLArc, 588.9ms\n",
      "Speed: 2.0ms preprocess, 588.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 players, 1 referee, 1 ball, 1118.0ms\n",
      "Speed: 2.0ms preprocess, 1118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 TLC, 1 TL6MC, 1 TL6ML, 1 TL18MC, 1 TL18ML, 1 LMC, 1 BL18MC, 1 BLArc, 623.8ms\n",
      "Speed: 2.8ms preprocess, 623.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players_id</th>\n",
       "      <th>displacement (km)</th>\n",
       "      <th>speed (m/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>player0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>player1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player2</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>player3</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>player4</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>player5</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>player6</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>player7</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>player8</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>player9</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>player10</td>\n",
       "      <td>1.87</td>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>player11</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>player12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>player13</td>\n",
       "      <td>14.00</td>\n",
       "      <td>14.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>player14</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>player15</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>player16</td>\n",
       "      <td>15.38</td>\n",
       "      <td>15.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>player17</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>player18</td>\n",
       "      <td>23.12</td>\n",
       "      <td>23.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>player19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   players_id  displacement (km)  speed (m/s)\n",
       "0     player0               1.16         1.16\n",
       "1     player1               0.40         0.40\n",
       "2     player2               1.58         1.58\n",
       "3     player3               0.53         0.53\n",
       "4     player4               0.39         0.39\n",
       "5     player5               1.51         1.51\n",
       "6     player6               0.94         0.94\n",
       "7     player7               0.43         0.43\n",
       "8     player8               1.51         1.51\n",
       "9     player9               0.96         0.96\n",
       "10   player10               1.87         1.87\n",
       "11   player11               0.57         0.57\n",
       "12   player12               0.35         0.35\n",
       "13   player13              14.00        14.00\n",
       "14   player14               0.47         0.47\n",
       "15   player15               0.98         0.98\n",
       "16   player16              15.38        15.38\n",
       "17   player17               1.23         1.23\n",
       "18   player18              23.12        23.12\n",
       "19   player19               0.00         0.00"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize frame counter\n",
    "frame_nbr = 0\n",
    "\n",
    "# Set keypoints average displacement tolerance level (in pixels) [set to -1 to always update homography matrix]\n",
    "keypoints_displacement_mean_tol = 10\n",
    "\n",
    "# Set confidence thresholds for players and field keypoints detections\n",
    "player_model_conf_thresh = 0.60\n",
    "keypoints_model_conf_thresh = 0.70\n",
    "\n",
    "# Set variable to record the time when we processed last frame \n",
    "prev_frame_time = 0\n",
    "# Set variable to record the time at which we processed current frame \n",
    "new_frame_time = 0\n",
    "\n",
    "# Store the ball track history\n",
    "ball_track_history = {'src':[],\n",
    "                      'dst':[]\n",
    "}\n",
    "\n",
    "# Count consecutive frames with no ball detected\n",
    "nbr_frames_no_ball = 0\n",
    "# Threshold for number of frames with no ball to reset ball track (frames)\n",
    "nbr_frames_no_ball_thresh = 30\n",
    "# Distance threshold for ball tracking (pixels)\n",
    "ball_track_dist_thresh = 100\n",
    "# Maximum ball track length (detections)\n",
    "max_track_length = 35\n",
    "\n",
    "# A list to store previous player positions\n",
    "prev_player_positions = []\n",
    "\n",
    "# Dictionary to store all players total displacement and speed\n",
    "dict_displacement_speed ={\n",
    "    \"players_id\" : [f\"player{i}\" for i in range(20)],\n",
    "    \"displacement (km)\" : [0 for i in range(20)],\n",
    "    \"speed (m/s)\" : [0 for i in range(20)]\n",
    "}\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Update frame counter\n",
    "    frame_nbr += 1\n",
    "\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # Reset tactical map image for each new frame\n",
    "    tac_map_copy = tac_map.copy()\n",
    "\n",
    "    # Reset ball tracks\n",
    "    if nbr_frames_no_ball>nbr_frames_no_ball_thresh:\n",
    "            ball_track_history['dst'] = []\n",
    "            ball_track_history['src'] = []\n",
    "\n",
    "    # Process the frame if it was successfuly read\n",
    "    if success:\n",
    "        \n",
    "        #################### Part 1 ####################\n",
    "        # Object Detection & Coordiante Transofrmation #\n",
    "        ################################################\n",
    "\n",
    "        # Run YOLOv8 players inference on the frame\n",
    "        results_players = model_players(frame, conf=player_model_conf_thresh)\n",
    "        # Run YOLOv8 field keypoints inference on the frame\n",
    "        results_keypoints = model_keypoints(frame, conf=keypoints_model_conf_thresh)\n",
    "\n",
    "        ## Extract detections information\n",
    "        bboxes_p = results_players[0].boxes.xyxy.cpu().numpy()                          # Detected players, referees and ball (x,y,x,y) bounding boxes\n",
    "        bboxes_p_c = results_players[0].boxes.xywh.cpu().numpy()                        # Detected players, referees and ball (x,y,w,h) bounding boxes    \n",
    "        labels_p = list(results_players[0].boxes.cls.cpu().numpy())                     # Detected players, referees and ball labels list\n",
    "        confs_p = list(results_players[0].boxes.conf.cpu().numpy())                     # Detected players, referees and ball confidence level\n",
    "        \n",
    "        bboxes_k = results_keypoints[0].boxes.xyxy.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        bboxes_k_c = results_keypoints[0].boxes.xywh.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        labels_k = list(results_keypoints[0].boxes.cls.cpu().numpy())                   # Detected field keypoints labels list\n",
    "\n",
    "        # Convert detected numerical labels to alphabetical labels\n",
    "        detected_labels = [classes_names_dic[i] for i in labels_k]\n",
    "\n",
    "        # Extract detected field keypoints coordiantes on the current frame\n",
    "        detected_labels_src_pts = np.array([list(np.round(bboxes_k_c[i][:2]).astype(int)) for i in range(bboxes_k_c.shape[0])])\n",
    "\n",
    "        # Get the detected field keypoints coordinates on the tactical map\n",
    "        detected_labels_dst_pts = np.array([keypoints_map_pos[i] for i in detected_labels])\n",
    "\n",
    "\n",
    "        ## Calculate Homography transformation matrix when more than 4 keypoints are detected\n",
    "        if len(detected_labels) > 3:\n",
    "            # Always calculate homography matrix on the first frame\n",
    "            if frame_nbr > 1:\n",
    "                # Determine common detected field keypoints between previous and current frames\n",
    "                common_labels = set(detected_labels_prev) & set(detected_labels)\n",
    "                # When at least 4 common keypoints are detected, determine if they are displaced on average beyond a certain tolerance level\n",
    "                if len(common_labels) > 3:\n",
    "                    common_label_idx_prev = [detected_labels_prev.index(i) for i in common_labels]   # Get labels indexes of common detected keypoints from previous frame\n",
    "                    common_label_idx_curr = [detected_labels.index(i) for i in common_labels]        # Get labels indexes of common detected keypoints from current frame\n",
    "                    coor_common_label_prev = detected_labels_src_pts_prev[common_label_idx_prev]     # Get labels coordiantes of common detected keypoints from previous frame\n",
    "                    coor_common_label_curr = detected_labels_src_pts[common_label_idx_curr]          # Get labels coordiantes of common detected keypoints from current frame\n",
    "                    coor_error = mean_squared_error(coor_common_label_prev, coor_common_label_curr)  # Calculate error between previous and current common keypoints coordinates\n",
    "                    update_homography = coor_error > keypoints_displacement_mean_tol                 # Check if error surpassed the predefined tolerance level\n",
    "                else:\n",
    "                    update_homography = True                                                         \n",
    "            else:\n",
    "                update_homography = True\n",
    "\n",
    "            if  update_homography:\n",
    "                h, mask = cv2.findHomography(detected_labels_src_pts,                   # Calculate homography matrix\n",
    "                                              detected_labels_dst_pts)                  \n",
    "            \n",
    "            detected_labels_prev = detected_labels.copy()                               # Save current detected keypoint labels for next frame\n",
    "            detected_labels_src_pts_prev = detected_labels_src_pts.copy()               # Save current detected keypoint coordiantes for next frame\n",
    "\n",
    "            bboxes_p_c_0 = bboxes_p_c[[i==0 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected players (label 0)\n",
    "            bboxes_p_c_2 = bboxes_p_c[[i==2 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected ball(s) (label 2)\n",
    "\n",
    "            # Get coordinates of detected players on frame (x_cencter, y_center+h/2)\n",
    "            detected_ppos_src_pts = bboxes_p_c_0[:,:2]  + np.array([[0]*bboxes_p_c_0.shape[0], bboxes_p_c_0[:,3]/2]).transpose()\n",
    "            # Get coordinates of the first detected ball (x_center, y_center)\n",
    "            detected_ball_src_pos = bboxes_p_c_2[0,:2] if bboxes_p_c_2.shape[0]>0 else None\n",
    "\n",
    "            # Transform players coordinates from frame plane to tactical map plance using the calculated Homography matrix\n",
    "            pred_dst_pts = []                                                           # Initialize players tactical map coordiantes list\n",
    "            for pt in detected_ppos_src_pts:                                            # Loop over players frame coordiantes\n",
    "                pt = np.append(np.array(pt), np.array([1]), axis=0)                     # Covert to homogeneous coordiantes\n",
    "                dest_point = np.matmul(h, np.transpose(pt))                              # Apply homography transofrmation\n",
    "                dest_point = dest_point/dest_point[2]                                   # Revert to 2D-coordiantes\n",
    "                pred_dst_pts.append(list(np.transpose(dest_point)[:2]))                 # Update players tactical map coordiantes list\n",
    "            pred_dst_pts = np.array(pred_dst_pts)\n",
    "            #print(\"player detected\", pred_dst_pts)\n",
    "                \n",
    "            # Calculate player total displacement and average speed\n",
    "            if len(prev_player_positions) != 0:\n",
    "                pred_dst_pts = match_players_positions(prev_player_positions, pred_dst_pts)\n",
    "                for i in range(min(len(pred_dst_pts), len(prev_player_positions))):\n",
    "                    # Calculate the distance between current and previous player positions\n",
    "                    displacement = np.linalg.norm(pred_dst_pts[i] - prev_player_positions[i])\n",
    "                    dict_displacement_speed[\"displacement (km)\"][i] += displacement*((120*90)/(546*314)) # 120 est la dimension (longueur) du terrain\n",
    "                    dict_displacement_speed[\"speed (m/s)\"][i] += (displacement*((120*90)/(546*314))/time_between_frames) # 90 est la dimension (largeur) du terrain\n",
    "            # Update previous player positions\n",
    "            prev_player_positions = pred_dst_pts.copy()\n",
    "            \n",
    "            if frame_nbr == 30:\n",
    "                break\n",
    "\n",
    "# Calculate Average speed for each player\n",
    "for i in range(20):\n",
    "    dict_displacement_speed[\"speed (m/s)\"][i] = round(dict_displacement_speed[\"speed (m/s)\"][i]/frame_nbr, 2)\n",
    "    dict_displacement_speed[\"displacement (km)\"][i] = round(dict_displacement_speed[\"displacement (km)\"][i], 2)\n",
    "# Créer un DataFrame à partir du dictionnaire dict_displacement_speed\n",
    "df = pd.DataFrame(dict_displacement_speed)\n",
    "# Afficher le DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize frame counter\n",
    "frame_nbr = 0\n",
    "\n",
    "# Set keypoints average displacement tolerance level (in pixels) [set to -1 to always update homography matrix]\n",
    "keypoints_displacement_mean_tol = 10\n",
    "\n",
    "# Set confidence thresholds for players and field keypoints detections\n",
    "player_model_conf_thresh = 0.60\n",
    "keypoints_model_conf_thresh = 0.70\n",
    "\n",
    "# Set variable to record the time when we processed last frame \n",
    "prev_frame_time = 0\n",
    "# Set variable to record the time at which we processed current frame \n",
    "new_frame_time = 0\n",
    "\n",
    "# Store the ball track history\n",
    "ball_track_history = {'src':[],\n",
    "                      'dst':[]\n",
    "}\n",
    "\n",
    "# Count consecutive frames with no ball detected\n",
    "nbr_frames_no_ball = 0\n",
    "# Threshold for number of frames with no ball to reset ball track (frames)\n",
    "nbr_frames_no_ball_thresh = 30\n",
    "# Distance threshold for ball tracking (pixels)\n",
    "ball_track_dist_thresh = 100\n",
    "# Maximum ball track length (detections)\n",
    "max_track_length = 35\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "\n",
    "    # Update frame counter\n",
    "    frame_nbr += 1\n",
    "\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # Reset tactical map image for each new frame\n",
    "    tac_map_copy = tac_map.copy()\n",
    "\n",
    "    # Reset ball tracks\n",
    "    if nbr_frames_no_ball>nbr_frames_no_ball_thresh:\n",
    "            ball_track_history['dst'] = []\n",
    "            ball_track_history['src'] = []\n",
    "\n",
    "    # Process the frame if it was successfuly read\n",
    "    if success:\n",
    "        \n",
    "        #################### Part 1 ####################\n",
    "        # Object Detection & Coordiante Transofrmation #\n",
    "        ################################################\n",
    "\n",
    "        # Run YOLOv8 players inference on the frame\n",
    "        results_players = model_players(frame, conf=player_model_conf_thresh)\n",
    "        # Run YOLOv8 field keypoints inference on the frame\n",
    "        results_keypoints = model_keypoints(frame, conf=keypoints_model_conf_thresh)\n",
    "\n",
    "        ## Extract detections information\n",
    "        bboxes_p = results_players[0].boxes.xyxy.cpu().numpy()                          # Detected players, referees and ball (x,y,x,y) bounding boxes\n",
    "        bboxes_p_c = results_players[0].boxes.xywh.cpu().numpy()                        # Detected players, referees and ball (x,y,w,h) bounding boxes    \n",
    "        labels_p = list(results_players[0].boxes.cls.cpu().numpy())                     # Detected players, referees and ball labels list\n",
    "        confs_p = list(results_players[0].boxes.conf.cpu().numpy())                     # Detected players, referees and ball confidence level\n",
    "        \n",
    "        bboxes_k = results_keypoints[0].boxes.xyxy.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        bboxes_k_c = results_keypoints[0].boxes.xywh.cpu().numpy()                        # Detected field keypoints (x,y,w,h) bounding boxes\n",
    "        labels_k = list(results_keypoints[0].boxes.cls.cpu().numpy())                   # Detected field keypoints labels list\n",
    "\n",
    "        # Convert detected numerical labels to alphabetical labels\n",
    "        detected_labels = [classes_names_dic[i] for i in labels_k]\n",
    "\n",
    "        # Extract detected field keypoints coordiantes on the current frame\n",
    "        detected_labels_src_pts = np.array([list(np.round(bboxes_k_c[i][:2]).astype(int)) for i in range(bboxes_k_c.shape[0])])\n",
    "\n",
    "        # Get the detected field keypoints coordinates on the tactical map\n",
    "        detected_labels_dst_pts = np.array([keypoints_map_pos[i] for i in detected_labels])\n",
    "\n",
    "\n",
    "        ## Calculate Homography transformation matrix when more than 4 keypoints are detected\n",
    "        if len(detected_labels) > 3:\n",
    "            # Always calculate homography matrix on the first frame\n",
    "            if frame_nbr > 1:\n",
    "                # Determine common detected field keypoints between previous and current frames\n",
    "                common_labels = set(detected_labels_prev) & set(detected_labels)\n",
    "                # When at least 4 common keypoints are detected, determine if they are displaced on average beyond a certain tolerance level\n",
    "                if len(common_labels) > 3:\n",
    "                    common_label_idx_prev = [detected_labels_prev.index(i) for i in common_labels]   # Get labels indexes of common detected keypoints from previous frame\n",
    "                    common_label_idx_curr = [detected_labels.index(i) for i in common_labels]        # Get labels indexes of common detected keypoints from current frame\n",
    "                    coor_common_label_prev = detected_labels_src_pts_prev[common_label_idx_prev]     # Get labels coordiantes of common detected keypoints from previous frame\n",
    "                    coor_common_label_curr = detected_labels_src_pts[common_label_idx_curr]          # Get labels coordiantes of common detected keypoints from current frame\n",
    "                    coor_error = mean_squared_error(coor_common_label_prev, coor_common_label_curr)  # Calculate error between previous and current common keypoints coordinates\n",
    "                    update_homography = coor_error > keypoints_displacement_mean_tol                 # Check if error surpassed the predefined tolerance level\n",
    "                else:\n",
    "                    update_homography = True                                                         \n",
    "            else:\n",
    "                update_homography = True\n",
    "\n",
    "            if  update_homography:\n",
    "                h, mask = cv2.findHomography(detected_labels_src_pts,                   # Calculate homography matrix\n",
    "                                              detected_labels_dst_pts)                  \n",
    "            \n",
    "            detected_labels_prev = detected_labels.copy()                               # Save current detected keypoint labels for next frame\n",
    "            detected_labels_src_pts_prev = detected_labels_src_pts.copy()               # Save current detected keypoint coordiantes for next frame\n",
    "\n",
    "            bboxes_p_c_0 = bboxes_p_c[[i==0 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected players (label 0)\n",
    "            bboxes_p_c_2 = bboxes_p_c[[i==2 for i in labels_p],:]                       # Get bounding boxes information (x,y,w,h) of detected ball(s) (label 2)\n",
    "\n",
    "            # Get coordinates of detected players on frame (x_cencter, y_center+h/2)\n",
    "            detected_ppos_src_pts = bboxes_p_c_0[:,:2]  + np.array([[0]*bboxes_p_c_0.shape[0], bboxes_p_c_0[:,3]/2]).transpose()\n",
    "            # Get coordinates of the first detected ball (x_center, y_center)\n",
    "            detected_ball_src_pos = bboxes_p_c_2[0,:2] if bboxes_p_c_2.shape[0]>0 else None\n",
    "\n",
    "            # Transform players coordinates from frame plane to tactical map plance using the calculated Homography matrix\n",
    "            pred_dst_pts = []                                                           # Initialize players tactical map coordiantes list\n",
    "            for pt in detected_ppos_src_pts:                                            # Loop over players frame coordiantes\n",
    "                pt = np.append(np.array(pt), np.array([1]), axis=0)                     # Covert to homogeneous coordiantes\n",
    "                dest_point = np.matmul(h, np.transpose(pt))                              # Apply homography transofrmation\n",
    "                dest_point = dest_point/dest_point[2]                                   # Revert to 2D-coordiantes\n",
    "                pred_dst_pts.append(list(np.transpose(dest_point)[:2]))                 # Update players tactical map coordiantes list\n",
    "            pred_dst_pts = np.array(pred_dst_pts)\n",
    "\n",
    "            # Transform ball coordinates from frame plane to tactical map plane using the calculated Homography matrix\n",
    "            if detected_ball_src_pos is not None:\n",
    "                pt = np.append(np.array(detected_ball_src_pos), np.array([1]), axis=0)\n",
    "                dest_point = np.matmul(h, np.transpose(pt))\n",
    "                dest_point = dest_point/dest_point[2]\n",
    "                detected_ball_dst_pos = np.transpose(dest_point)\n",
    "\n",
    "                # Update track ball position history\n",
    "                if len(ball_track_history['src'])>0 :\n",
    "                    if np.linalg.norm(detected_ball_src_pos-ball_track_history['src'][-1])<ball_track_dist_thresh:\n",
    "                        ball_track_history['src'].append((int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1])))\n",
    "                        ball_track_history['dst'].append((int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1])))\n",
    "                    else:\n",
    "                        ball_track_history['src']=[(int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1]))]\n",
    "                        ball_track_history['dst']=[(int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1]))]\n",
    "                else:\n",
    "                    ball_track_history['src'].append((int(detected_ball_src_pos[0]), int(detected_ball_src_pos[1])))\n",
    "                    ball_track_history['dst'].append((int(detected_ball_dst_pos[0]), int(detected_ball_dst_pos[1])))\n",
    "            # Remove oldest tracked ball postion if track exceedes threshold        \n",
    "            if len(ball_track_history) > max_track_length:\n",
    "                    ball_track_history['src'].pop(0)\n",
    "                    ball_track_history['dst'].pop(0)\n",
    "\n",
    "        ######### Part 2 ########## \n",
    "        # Players Team Prediction #\n",
    "        ###########################\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                                      # Convert frame to RGB\n",
    "        obj_palette_list = []                                                                   # Initialize players color palette list\n",
    "        palette_interval = (0,5)                                                                # Color interval to extract from dominant colors palette (1rd to 5th color)\n",
    "        annotated_frame = frame                                                                 # Create annotated frame \n",
    "\n",
    "        ## Loop over detected players (label 0) and extract dominant colors palette based on defined interval\n",
    "        for i, j in enumerate(list(results_players[0].boxes.cls.cpu().numpy())):\n",
    "            if int(j) == 0:\n",
    "                bbox = results_players[0].boxes.xyxy.cpu().numpy()[i,:]                         # Get bbox info (x,y,x,y)\n",
    "                obj_img = frame_rgb[int(bbox[1]):int(bbox[3]), int(bbox[0]):int(bbox[2])]       # Crop bbox out of the frame\n",
    "                obj_img_w, obj_img_h = obj_img.shape[1], obj_img.shape[0]\n",
    "                center_filter_x1 = np.max([(obj_img_w//2)-(obj_img_w//5), 1])\n",
    "                center_filter_x2 = (obj_img_w//2)+(obj_img_w//5)\n",
    "                center_filter_y1 = np.max([(obj_img_h//3)-(obj_img_h//5), 1])\n",
    "                center_filter_y2 = (obj_img_h//3)+(obj_img_h//5)\n",
    "                center_filter = obj_img[center_filter_y1:center_filter_y2, \n",
    "                                        center_filter_x1:center_filter_x2]\n",
    "                obj_pil_img = Image.fromarray(np.uint8(center_filter))                          # Convert to pillow image\n",
    "                    \n",
    "                reduced = obj_pil_img.convert(\"P\", palette=Image.Palette.WEB)                   # Convert to web palette (216 colors)\n",
    "                palette = reduced.getpalette()                                                  # Get palette as [r,g,b,r,g,b,...]\n",
    "                palette = [palette[3*n:3*n+3] for n in range(256)]                              # Group 3 by 3 = [[r,g,b],[r,g,b],...]\n",
    "                color_count = [(n, palette[m]) for n,m in reduced.getcolors()]                  # Create list of palette colors with their frequency\n",
    "                RGB_df = pd.DataFrame(color_count, columns = ['cnt', 'RGB']).sort_values(       # Create dataframe based on defined palette interval\n",
    "                                      by = 'cnt', ascending = False).iloc[\n",
    "                                          palette_interval[0]:palette_interval[1],:]\n",
    "                palette = list(RGB_df.RGB)                                                      # Convert palette to list (for faster processing)\n",
    "                annotated_frame = cv2.rectangle(annotated_frame,                                # Add center filter bbox annotations\n",
    "                                                (int(bbox[0])+center_filter_x1, \n",
    "                                                 int(bbox[1])+ center_filter_y1),  \n",
    "                                                (int(bbox[0])+center_filter_x2, \n",
    "                                                 int(bbox[1])+center_filter_y2), (0,0,0), 2)\n",
    "                \n",
    "                # Update detected players color palette list\n",
    "                obj_palette_list.append(palette)\n",
    "        \n",
    "        ## Calculate distances between each color from every detected player color palette and the predefined teams colors\n",
    "        players_distance_features = []\n",
    "        # Loop over detected players extracted color palettes\n",
    "        for palette in obj_palette_list:\n",
    "            palette_distance = []\n",
    "            palette_lab = [skimage.color.rgb2lab([i/255 for i in color]) for color in palette]  # Convert colors to L*a*b* space\n",
    "            # Loop over colors in palette\n",
    "            for color in palette_lab:\n",
    "                distance_list = []\n",
    "                # Loop over predefined list of teams colors\n",
    "                for c in color_list_lab:\n",
    "                    #distance = np.linalg.norm([i/255 - j/255 for i,j in zip(color,c)])\n",
    "                    distance = skimage.color.deltaE_cie76(color, c)                             # Calculate Euclidean distance in Lab color space\n",
    "                    distance_list.append(distance)                                              # Update distance list for current color\n",
    "                palette_distance.append(distance_list)                                          # Update distance list for current palette\n",
    "            players_distance_features.append(palette_distance)                                  # Update distance features list\n",
    "\n",
    "        ## Predict detected players teams based on distance features\n",
    "        players_teams_list = []\n",
    "        # Loop over players distance features\n",
    "        for distance_feats in players_distance_features:\n",
    "            vote_list=[]\n",
    "            # Loop over distances for each color \n",
    "            for dist_list in distance_feats:\n",
    "                team_idx = dist_list.index(min(dist_list))//nbr_team_colors                     # Assign team index for current color based on min distance\n",
    "                vote_list.append(team_idx)                                                      # Update vote voting list with current color team prediction\n",
    "            players_teams_list.append(max(vote_list, key=vote_list.count))                      # Predict current player team by vote counting\n",
    "\n",
    "\n",
    "        #################### Part 3 #####################\n",
    "        # Updated Frame & Tactical Map With Annotations #\n",
    "        #################################################\n",
    "\n",
    "        ball_color_bgr = (0,0,255)                                                                          # Color (GBR) for ball annotation on tactical map\n",
    "        j=0                                                                                                 # Initializing counter of detected players\n",
    "        palette_box_size = 10                                                                               # Set color box size in pixels (for display)\n",
    "        \n",
    "\n",
    "        # Loop over all detected object by players detection model\n",
    "        for i in range(bboxes_p.shape[0]):\n",
    "            conf = confs_p[i]                                                                               # Get confidence of current detected object\n",
    "            if labels_p[i]==0:                                                                              # Display annotation for detected players (label 0)\n",
    "                \n",
    "                # Display extracted color palette for each detected player\n",
    "                palette = obj_palette_list[j]                                                               # Get color palette of the detected player\n",
    "                for k, c in enumerate(palette):\n",
    "                    c_bgr = c[::-1]                                                                         # Convert color to BGR\n",
    "                    annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,2])+3,                 # Add color palette annotation on frame\n",
    "                                                            int(bboxes_p[i,1])+k*palette_box_size),\n",
    "                                                            (int(bboxes_p[i,2])+palette_box_size,\n",
    "                                                            int(bboxes_p[i,1])+(palette_box_size)*(k+1)),\n",
    "                                                              c_bgr, -1)\n",
    "\n",
    "                team_name = list(colors_dic.keys())[players_teams_list[j]]                                  # Get detected player team prediction\n",
    "                color_rgb = colors_dic[team_name][0]                                                        # Get detected player team color\n",
    "                color_bgr = color_rgb[::-1]                                                                 # Convert color to bgr\n",
    "\n",
    "                annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,0]), int(bboxes_p[i,1])),  # Add bbox annotations with team colors\n",
    "                                                (int(bboxes_p[i,2]), int(bboxes_p[i,3])), color_bgr, 1)\n",
    "                \n",
    "                cv2.putText(annotated_frame, team_name + f\" {conf:.2f}\",                                    # Add team name annotations\n",
    "                             (int(bboxes_p[i,0]), int(bboxes_p[i,1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                               color_bgr, 2)\n",
    "                \n",
    "                # Add tactical map player postion color coded annotation if more than 3 field keypoints are detected\n",
    "                if len(detected_labels_src_pts)>3:\n",
    "                    tac_map_copy = cv2.circle(tac_map_copy, (int(pred_dst_pts[j][0]),int(pred_dst_pts[j][1])),\n",
    "                                          radius=5, color=color_bgr, thickness=-1)\n",
    "\n",
    "                j+=1                                                                                        # Update players counter\n",
    "            else:                                                                                           # Display annotation for otehr detections (label 1, 2)\n",
    "                annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_p[i,0]), int(bboxes_p[i,1])),  # Add white colored bbox annotations\n",
    "                                                 (int(bboxes_p[i,2]), int(bboxes_p[i,3])), (255,255,255), 1)\n",
    "                cv2.putText(annotated_frame, labels_dic[labels_p[i]] + f\" {conf:.2f}\",                      # Add white colored label text annotations\n",
    "                            (int(bboxes_p[i,0]), int(bboxes_p[i,1])-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                              (255,255,255), 2)\n",
    "\n",
    "                # Add tactical map ball postion annotation if detected\n",
    "                if detected_ball_src_pos is not None:\n",
    "                    tac_map_copy = cv2.circle(tac_map_copy, (int(detected_ball_dst_pos[0]), \n",
    "                                                   int(detected_ball_dst_pos[1])), radius=5, \n",
    "                                                   color=ball_color_bgr, thickness=3)\n",
    "        for i in range(bboxes_k.shape[0]):\n",
    "            annotated_frame = cv2.rectangle(annotated_frame, (int(bboxes_k[i,0]), int(bboxes_k[i,1])),  # Add bbox annotations with team colors\n",
    "                                        (int(bboxes_k[i,2]), int(bboxes_k[i,3])), (0,0,0), 1)\n",
    "        \n",
    "        # Plot the ball tracks on tactical map\n",
    "        if len(ball_track_history['src'])>0:\n",
    "            points = np.hstack(ball_track_history['dst']).astype(np.int32).reshape((-1, 1, 2))\n",
    "            tac_map_copy = cv2.polylines(tac_map_copy, [points], isClosed=False, color=(0, 0, 100), thickness=2)\n",
    "        \n",
    "        # Combine annotated frame and tactical map in one image with colored border separation\n",
    "        border_color = [255,255,255]                                                                        # Set border color (BGR)\n",
    "        annotated_frame=cv2.copyMakeBorder(annotated_frame, 40, 10, 10, 10,                                 # Add borders to annotated frame\n",
    "                                            cv2.BORDER_CONSTANT, value=border_color)\n",
    "        tac_map_copy = cv2.copyMakeBorder(tac_map_copy, 70, 50, 10, 10, cv2.BORDER_CONSTANT,                # Add borders to tactical map \n",
    "                                           value=border_color)      \n",
    "        tac_map_copy = cv2.resize(tac_map_copy, (tac_map_copy.shape[1], annotated_frame.shape[0]))          # Resize tactical map\n",
    "        final_img = cv2.hconcat((annotated_frame, tac_map_copy))                                            # Concatenate both images\n",
    "        ## Add info annotation\n",
    "        cv2.putText(final_img, \"Tactical Map\", (1370,60), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "        cv2.putText(final_img, \"Press 'p' to pause & 'q' to quit\", (820,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "\n",
    "        new_frame_time = time.time()                                                                        # Get time after finished processing current frame\n",
    "        fps = 1/(new_frame_time-prev_frame_time)                                                            # Calculate FPS as 1/(frame proceesing duration)\n",
    "        prev_frame_time = new_frame_time                                                                    # Save current time to be used in next frame\n",
    "        cv2.putText(final_img, \"FPS: \" + str(int(fps)), (20,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,0,0), 2)\n",
    "        \n",
    "        # Display the final annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Players and Field Keypoints Detection with Team Prediction and Tactical Map\",    \n",
    "                    final_img)\n",
    "\n",
    "        # Treat keyboard user inputs (\"p\" for pause/unpause & \"q\" for quit)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv2.waitKey(-1) #wait until any key is pressed\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
